{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de5f8a96-093b-47ed-93b6-9a2ff2794917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks Table Quality Assessment using Native PySpark\n",
    "\n",
    "## Overview  \n",
    "This notebook performs automated table quality assessment at scale using native PySpark capabilities on Databricks. It leverages distributed compute for terabyte-scale data analysis while avoiding raw data exposure.  \n",
    "\n",
    "### Key Features:  \n",
    "- **Metadata Assessment**: Existence checks, size metrics, partition analysis  \n",
    "- **Schema Inspection**: Data type validation and change history tracking  \n",
    "- **Data Integrity**: Column-level checks for illegal characters, null ratios, and length validation  \n",
    "- **Scalable Design**: DataFrame transformations for distributed processing  \n",
    "- **Security**: No raw data exposure, metadata-only reporting  \n",
    "\n",
    "### Environment Requirements:  \n",
    "- Databricks Runtime 13.3+ with PySpark 3.x  \n",
    "- Delta Lake and Parquet table support  \n",
    "- Cluster with sufficient resources for parallel processing  \n",
    "\n",
    "**Author**: Jhonathan Pauca Joya  \n",
    "**Rol**: MLOPS Eng.  \n",
    "**University**: Universidad Nacional Mayor de San Marcos  \n",
    "**Program**: MaestrÃ­a  \n",
    "**Last Updated**: August 2025  \n",
    "**Version**: 1.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d216968-6cf5-41d0-9448-84be84c9083f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook configuration and input parameters\n",
    "# Add widgets for user input parameters\n",
    "\n",
    "\n",
    "# Create widgets for interactive parameter configuration\n",
    "dbutils.widgets.text(\"table_list\", \"catalog1.schema1.table1,catalog2.schema2.table2\", \"Comma-separated list of fully qualified table names\")\n",
    "dbutils.widgets.text(\"scan_partitions\", \"10\", \"Number of recent partitions to scan\")\n",
    "dbutils.widgets.dropdown(\"output_format\", \"table\", [\"table\", \"json\", \"csv\", \"delta\"], \"Output format for results\")\n",
    "dbutils.widgets.text(\"size_threshold_gb\", \"50\", \"Table size threshold in GB for recommendations\")\n",
    "\n",
    "\n",
    "# Retrieve widget values\n",
    "table_list_str = dbutils.widgets.get(\"table_list\")\n",
    "scan_partitions = int(dbutils.widgets.get(\"scan_partitions\"))\n",
    "output_format = dbutils.widgets.get(\"output_format\")\n",
    "size_threshold_gb = float(dbutils.widgets.get(\"size_threshold_gb\"))\n",
    "\n",
    "\n",
    "# Parse table list from comma-separated string\n",
    "table_list = [table.strip() for table in table_list_str.split(\",\") if table.strip()]\n",
    "\n",
    "\n",
    "print(f\"Configuration loaded:\")\n",
    "print(f\"- Tables to assess: {len(table_list)}\")\n",
    "print(f\"- Partition scan depth: {scan_partitions}\")\n",
    "print(f\"- Output format: {output_format}\")\n",
    "print(f\"- Size threshold: {size_threshold_gb} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e436014a-61e7-4765-a33c-5a147bf981b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries and initialize Spark session\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import (\n",
    "    col, length, trim, max as spark_max, min as spark_min, count, \n",
    "    when, isnan, isnull, regexp_extract, regexp_replace, sum as spark_sum,\n",
    "    avg, stddev, first, last, collect_list, concat_ws, lit, size, from_json,\n",
    "    current_timestamp, date_format, udf, lower\n",
    ")\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, BooleanType, ArrayType, MapType\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "import re\n",
    "import json\n",
    "from decimal import Decimal\n",
    "from typing import List, Dict, Any, Iterator\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Initialize Spark session with optimized configuration for quality assessment\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TableQualityAssessment\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.skewJoin.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "print(f\"Spark session initialized: {spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21a7582f-f3b4-43af-a32b-bfeefca23df9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Utility Functions for Table Metadata Assessment\n",
    "\n",
    "def decimal_default(obj):\n",
    "    if isinstance(obj, Decimal):\n",
    "        return float(obj)\n",
    "    raise TypeError(f\"Object of type {type(obj).__name__} is not JSON serializable\")\n",
    "\n",
    "def table_exists(full_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a table exists in the catalog.\n",
    "    \n",
    "    Args:\n",
    "        full_name: Fully qualified table name (catalog.schema.table)\n",
    "    \n",
    "    Returns:\n",
    "        Boolean indicating table existence\n",
    "    \"\"\"\n",
    "    try:\n",
    "        spark.sql(f\"DESCRIBE TABLE {full_name}\").take(1)\n",
    "        return True\n",
    "    except AnalysisException as e:\n",
    "        if \"Table or view not found\" in str(e) or \"does not exist\" in str(e):\n",
    "            return False\n",
    "        raise e\n",
    "\n",
    "def get_table_size_gb(full_name: str) -> float:\n",
    "    \"\"\"\n",
    "    Get approximate table size in GB using DESCRIBE DETAIL.\n",
    "    \n",
    "    Args:\n",
    "        full_name: Fully qualified table name\n",
    "    \n",
    "    Returns:\n",
    "        Table size in GB\n",
    "    \"\"\"\n",
    "    try:\n",
    "        detail_df = spark.sql(f\"DESCRIBE DETAIL {full_name}\")\n",
    "        size_bytes = detail_df.select(\"sizeInBytes\").first()[0]\n",
    "        return round(size_bytes / (1024**3), 3) if size_bytes else 0.0\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not get size for {full_name}: {str(e)}\")\n",
    "        return 0.0\n",
    "\n",
    "def get_partition_columns(full_name: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    For a Delta table, uses DESCRIBE DETAIL to retrieve the\n",
    "    array of partition columns directly.\n",
    "    \"\"\"\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    \n",
    "    # DESCRIBE DETAIL returns a \"partitionColumns\" ArrayType column\n",
    "    detail_df = spark.sql(f\"DESCRIBE DETAIL {full_name}\")\n",
    "    detail = detail_df.select(\"partitionColumns\").first()\n",
    "    \n",
    "    # in case this isn't a Delta table or the field is missing:\n",
    "    return detail[\"partitionColumns\"] or []\n",
    "\n",
    "# Removed get_table_size_bypartition_gb method due to invalid SQL syntax\n",
    "# Will calculate partition size info using mean approach\n",
    "\n",
    "def get_table_schema_info(full_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract comprehensive schema information.\n",
    "    \n",
    "    Args:\n",
    "        full_name: Fully qualified table name\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with schema details\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get basic schema information\n",
    "        df = spark.table(full_name)\n",
    "        schema = df.schema\n",
    "        \n",
    "        schema_info = {\n",
    "            \"column_count\": len(schema.fields),\n",
    "            \"columns\": [],\n",
    "            \"data_types\": {}\n",
    "        }\n",
    "        \n",
    "        for field in schema.fields:\n",
    "            col_info = {\n",
    "                \"name\": field.name,\n",
    "                \"type\": str(field.dataType),\n",
    "                \"nullable\": field.nullable\n",
    "            }\n",
    "            schema_info[\"columns\"].append(col_info)\n",
    "            \n",
    "            # Group by data type\n",
    "            data_type = str(field.dataType)\n",
    "            if data_type not in schema_info[\"data_types\"]:\n",
    "                schema_info[\"data_types\"][data_type] = 0\n",
    "            schema_info[\"data_types\"][data_type] += 1\n",
    "            \n",
    "        return schema_info\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not get schema for {full_name}: {str(e)}\")\n",
    "        return {\"column_count\": 0, \"columns\": [], \"data_types\": {}}\n",
    "\n",
    "def get_table_schema_full(full_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract SQL schema info using DESCRIBE TABLE, including partition columns.\n",
    "    Returns a dict with 'columns' and 'partition_columns' (both lists of dicts with col_name, data_type, comment).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        desc_df = spark.sql(f\"DESCRIBE TABLE {full_name}\")\n",
    "        rows = desc_df.collect()\n",
    "        columns = []\n",
    "        partition_columns = []\n",
    "        in_partitions = False\n",
    "        for row in rows:\n",
    "            col_name = row['col_name']\n",
    "            data_type = row['data_type']\n",
    "            comment = row['comment']\n",
    "            if col_name is None:\n",
    "                continue\n",
    "            if col_name.strip().lower() == '# partition information':\n",
    "                in_partitions = True\n",
    "                continue\n",
    "            if col_name.strip().lower() == '# col_name':\n",
    "                continue\n",
    "            if col_name.strip().startswith('#'):\n",
    "                continue\n",
    "            entry = {'col_name': col_name, 'data_type': data_type, 'comment': comment}\n",
    "            if in_partitions:\n",
    "                partition_columns.append(entry)\n",
    "            else:\n",
    "                columns.append(entry)\n",
    "        return {'columns': columns, 'partition_columns': partition_columns}\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not get SQL schema for {full_name}: {str(e)}\")\n",
    "        return {'columns': [], 'partition_columns': []}\n",
    "\n",
    "def get_table_history_summary(full_name: str, max_records: int = 1000) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Get table history summary using DESCRIBE HISTORY.\n",
    "    \n",
    "    Args:\n",
    "        full_name: Fully qualified table name\n",
    "        max_records: Maximum number of history records to analyze\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with history summary\n",
    "    \"\"\"\n",
    "    try:\n",
    "        history_df = spark.sql(f\"DESCRIBE HISTORY {full_name} LIMIT {max_records}\")\n",
    "        \n",
    "        history_summary = {\n",
    "            \"total_operations\": 0,\n",
    "            \"operations\": {},\n",
    "            \"last_modified\": None,\n",
    "            \"created_by\": None\n",
    "        }\n",
    "        \n",
    "        if history_df.count() > 0:\n",
    "            history_data = history_df.collect()\n",
    "            history_summary[\"total_operations\"] = len(history_data)\n",
    "            \n",
    "            # Count operations by type\n",
    "            for row in history_data:\n",
    "                operation = row[\"operation\"] if row[\"operation\"] else \"UNKNOWN\"\n",
    "                if operation not in history_summary[\"operations\"]:\n",
    "                    history_summary[\"operations\"][operation] = 0\n",
    "                history_summary[\"operations\"][operation] += 1\n",
    "            \n",
    "            # Get latest modification info\n",
    "            latest = history_data[0]\n",
    "            history_summary[\"last_modified\"] = str(latest[\"timestamp\"]) if latest[\"timestamp\"] else None\n",
    "            history_summary[\"created_by\"] = latest[\"userName\"] if latest[\"userName\"] else \"Unknown\"\n",
    "        \n",
    "        return history_summary\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not get history for {full_name}: {str(e)}\")\n",
    "        return {\"total_operations\": 0, \"operations\": {}, \"last_modified\": None, \"created_by\": None}\n",
    "\n",
    "print(\"Utility functions for table metadata assessment loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e783c65-41aa-48d0-8807-63cbbde46462",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Column-Level Integrity Check Functions\n",
    "\n",
    "\n",
    "def analyze_column_quality(df: DataFrame, column_name: str, data_type: str, total_rows: int) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Perform comprehensive column quality analysis.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame for the table (filtered if needed)\n",
    "        column_name: Column to analyze\n",
    "        data_type: Data type of the column\n",
    "        total_rows: Total number of rows to use for metrics (precomputed, limited by scan_partitions)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with column quality metrics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if total_rows == 0:\n",
    "            return {\n",
    "                \"column_name\": column_name,\n",
    "                \"data_type\": data_type,\n",
    "                \"total_rows\": 0,\n",
    "                \"null_count\": 0,\n",
    "                \"null_ratio\": 0.0,\n",
    "                \"issues\": []\n",
    "            }\n",
    "        \n",
    "        column_stats = {\n",
    "            \"column_name\": column_name,\n",
    "            \"data_type\": data_type,\n",
    "            \"total_rows\": total_rows,\n",
    "            \"null_count\": 0,\n",
    "            \"null_ratio\": 0.0,\n",
    "            \"issues\": []\n",
    "        }\n",
    "        \n",
    "        # Calculate null statistics\n",
    "        null_count = df.filter(col(column_name).isNull()).count()\n",
    "        column_stats[\"null_count\"] = null_count\n",
    "        column_stats[\"null_ratio\"] = round(null_count / total_rows, 4)\n",
    "        \n",
    "        # String-specific checks\n",
    "        if \"string\" in data_type.lower():\n",
    "            string_analysis = analyze_string_column(df, column_name, total_rows)\n",
    "            column_stats.update(string_analysis)\n",
    "        \n",
    "        # Numeric-specific checks\n",
    "        elif any(num_type in data_type.lower() for num_type in [\"int\", \"long\", \"float\", \"double\", \"decimal\"]):\n",
    "            numeric_analysis = analyze_numeric_column(df, column_name)\n",
    "            column_stats.update(numeric_analysis)\n",
    "        \n",
    "        return column_stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"column_name\": column_name,\n",
    "            \"data_type\": data_type,\n",
    "            \"error\": str(e),\n",
    "            \"issues\": [f\"Analysis failed: {str(e)}\"]\n",
    "        }\n",
    "\n",
    "\n",
    "def analyze_string_column(df: DataFrame, column_name: str, total_rows: int) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyze string column for quality issues, including per-character illegal counts.\n",
    "    Args:\n",
    "        df: DataFrame containing the column\n",
    "        column_name: Name of string column to analyze\n",
    "        total_rows: Total number of rows for ratio calculations\n",
    "    Returns:\n",
    "        Dictionary with string-specific quality metrics, including per-character illegal counts\n",
    "    \"\"\"\n",
    "    string_stats = {}\n",
    "    \n",
    "    # Patterns for each illegal character type\n",
    "    illegal_patterns = {\n",
    "        'commas': r',' ,\n",
    "        'semicolons': r';' ,\n",
    "        'pipes': r'\\|',\n",
    "        'tabs': r'\\t',\n",
    "        'newlines': r'(\\n|\\r)'\n",
    "    }\n",
    "    \n",
    "    # Count for each illegal character type\n",
    "    for char_name, pattern in illegal_patterns.items():\n",
    "        count = df.filter(col(column_name).rlike(pattern)).count()\n",
    "        string_stats[char_name] = count\n",
    "    \n",
    "    # Total illegal chars (union, not sum, for ratio)\n",
    "    illegal_chars_pattern = r\"[,;|\\t\\n\\r]\"\n",
    "    illegal_chars_count = df.filter(col(column_name).rlike(illegal_chars_pattern)).count()\n",
    "    string_stats[\"illegal_chars_count\"] = illegal_chars_count\n",
    "    string_stats[\"illegal_chars_ratio\"] = round(illegal_chars_count / total_rows, 4)\n",
    "    \n",
    "    # Check for leading/trailing whitespace\n",
    "    whitespace_issues_count = df.filter(\n",
    "        (length(col(column_name)) != length(trim(col(column_name)))) &\n",
    "        col(column_name).isNotNull()\n",
    "    ).count()\n",
    "    string_stats[\"whitespace_issues_count\"] = whitespace_issues_count\n",
    "    string_stats[\"whitespace_issues_ratio\"] = round(whitespace_issues_count / total_rows, 4)\n",
    "    \n",
    "    # Calculate max length\n",
    "    max_length_result = df.agg(spark_max(length(col(column_name)))).first()\n",
    "    string_stats[\"max_length\"] = max_length_result[0] if max_length_result[0] else 0\n",
    "    \n",
    "    # Calculate average length (excluding nulls)\n",
    "    avg_length_result = df.filter(col(column_name).isNotNull()).agg(avg(length(col(column_name)))).first()\n",
    "    string_stats[\"avg_length\"] = round(avg_length_result[0], 2) if avg_length_result[0] else 0.0\n",
    "    \n",
    "    # Check for empty strings\n",
    "    empty_strings_count = df.filter(\n",
    "        (col(column_name) == \"\") | (col(column_name) == \" \")\n",
    "    ).count()\n",
    "    string_stats[\"empty_strings_count\"] = empty_strings_count\n",
    "    string_stats[\"empty_strings_ratio\"] = round(empty_strings_count / total_rows, 4)\n",
    "    \n",
    "    # Check for 'NULL' string values (case-insensitive)\n",
    "    null_string_count = df.filter(\n",
    "        col(column_name).isNotNull() & (lower(trim(col(column_name))) == \"null\")\n",
    "    ).count()\n",
    "    string_stats[\"null_string_count\"] = null_string_count\n",
    "    string_stats[\"null_string_ratio\"] = round(null_string_count / total_rows, 4)\n",
    "    \n",
    "    # Compile issues\n",
    "    issues = []\n",
    "    if string_stats[\"illegal_chars_ratio\"] > 0:\n",
    "        issues.append(f\"High illegal characters ratio: {string_stats['illegal_chars_ratio']:.2%}\")\n",
    "    if string_stats[\"whitespace_issues_ratio\"] > 0:\n",
    "        issues.append(f\"High whitespace issues ratio: {string_stats['whitespace_issues_ratio']:.2%}\")\n",
    "    if string_stats[\"max_length\"] > 256:\n",
    "        issues.append(f\"Very long strings detected: max length {string_stats['max_length']}\")\n",
    "    if string_stats[\"empty_strings_ratio\"] > 0:\n",
    "        issues.append(f\"High empty strings ratio: {string_stats['empty_strings_ratio']:.2%}\")\n",
    "    if string_stats[\"null_string_ratio\"] > 0:\n",
    "        issues.append(f\"High 'NULL' string ratio: {string_stats['null_string_ratio']:.2%}\")\n",
    "    \n",
    "    string_stats[\"issues\"] = issues\n",
    "    return string_stats\n",
    "\n",
    "\n",
    "def analyze_numeric_column(df: DataFrame, column_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyze numeric column for quality issues.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the column\n",
    "        column_name: Name of numeric column to analyze\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with numeric-specific quality metrics\n",
    "    \"\"\"\n",
    "    numeric_stats = {}\n",
    "    \n",
    "    # Basic numeric statistics\n",
    "    stats_result = df.filter(col(column_name).isNotNull()).agg(\n",
    "        spark_min(col(column_name)).alias(\"min_value\"),\n",
    "        spark_max(col(column_name)).alias(\"max_value\"),\n",
    "        avg(col(column_name)).alias(\"avg_value\"),\n",
    "        stddev(col(column_name)).alias(\"stddev_value\")\n",
    "    ).first()\n",
    "    \n",
    "    if stats_result:\n",
    "        numeric_stats[\"min_value\"] = stats_result[\"min_value\"]\n",
    "        numeric_stats[\"max_value\"] = stats_result[\"max_value\"]\n",
    "        numeric_stats[\"avg_value\"] = round(stats_result[\"avg_value\"], 4) if stats_result[\"avg_value\"] else None\n",
    "        numeric_stats[\"stddev_value\"] = round(stats_result[\"stddev_value\"], 4) if stats_result[\"stddev_value\"] else None\n",
    "    \n",
    "    # Check for infinite values\n",
    "    infinite_count = df.filter(\n",
    "        isnan(col(column_name)) | \n",
    "        (col(column_name) == float('inf')) | \n",
    "        (col(column_name) == float('-inf'))\n",
    "    ).count()\n",
    "    \n",
    "    numeric_stats[\"infinite_count\"] = infinite_count\n",
    "    \n",
    "    # Compile issues\n",
    "    issues = []\n",
    "    if infinite_count > 0:\n",
    "        issues.append(f\"Infinite/NaN values detected: {infinite_count}\")\n",
    "    \n",
    "    numeric_stats[\"issues\"] = issues\n",
    "    return numeric_stats\n",
    "\n",
    "\n",
    "print(\"Column-level integrity check functions loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b16e8bca-ec27-4a95-b140-d79003f0ec9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Main Table Assessment Orchestration\n",
    "\n",
    "def assess_table_quality(table_name: str, scan_partitions: int = 10) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Perform comprehensive table quality assessment.\n",
    "    \n",
    "    Args:\n",
    "        table_name: Fully qualified table name\n",
    "        scan_partitions: Number of recent partitions to analyze (limits partition count)\n",
    "    \n",
    "    Returns:\n",
    "        Complete assessment results dictionary\n",
    "    \"\"\"\n",
    "    assessment_start = datetime.now()\n",
    "    \n",
    "    result = {\n",
    "        \"table_name\": table_name,\n",
    "        \"assessment_timestamp\": assessment_start.isoformat(),\n",
    "        \"exists\": False,\n",
    "        \"metadata\": {},\n",
    "        \"column_analysis\": [],\n",
    "        \"partition_size_info\": [],\n",
    "        \"recommendations\": [],\n",
    "        \"assessment_duration_seconds\": 0\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Check table existence\n",
    "        if not table_exists(table_name):\n",
    "            result[\"recommendations\"].append(\"CRITICAL: Table does not exist\")\n",
    "            return result\n",
    "        \n",
    "        result[\"exists\"] = True\n",
    "        \n",
    "        # Step 2: Gather metadata\n",
    "        print(f\"Analyzing metadata for {table_name}...\")\n",
    "        metadata = {\n",
    "            \"size_gb\": get_table_size_gb(table_name),\n",
    "            \"partition_columns\": get_partition_columns(table_name),\n",
    "            \"schema_info\": get_table_schema_info(table_name),\n",
    "            \"schema_full\": get_table_schema_full(table_name),\n",
    "            \"history_summary\": get_table_history_summary(table_name)\n",
    "        }\n",
    "        result[\"metadata\"] = metadata\n",
    "        \n",
    "        # Step 3: Prepare DataFrame and filter by partitions if needed\n",
    "        df = spark.table(table_name)\n",
    "        partition_cols = metadata[\"partition_columns\"]\n",
    "        if not partition_cols or len(partition_cols) == 0:\n",
    "            # Not partitioned: use all rows\n",
    "            df_filtered = df\n",
    "            total_rows = df_filtered.count()\n",
    "            print(f\"Table is not partitioned. Using all {total_rows} rows for column analysis.\")\n",
    "            # No partition size info for unpartitioned tables\n",
    "            result[\"partition_size_info\"] = []\n",
    "        else:\n",
    "            # Partitioned: get last scan_partitions partition values from metadata\n",
    "            part_col = partition_cols[0]  # Only support single partition column for now\n",
    "            # Get distinct partition values, order descending, take N\n",
    "            part_values = [row[0] for row in df.select(part_col).distinct().orderBy(col(part_col).desc()).limit(scan_partitions).collect()]\n",
    "            df_filtered = df.filter(col(part_col).isin(part_values))\n",
    "            total_rows = df_filtered.count()\n",
    "            print(f\"Table is partitioned by {part_col}. Using last {len(part_values)} partitions ({total_rows} rows) for column analysis.\")\n",
    "            \n",
    "            # Calculate mean partition size using total table size and scan_partitions\n",
    "            total_size_gb = metadata[\"size_gb\"]\n",
    "            if scan_partitions > 0 and total_size_gb > 0:\n",
    "                mean_partition_size_gb = total_size_gb / scan_partitions\n",
    "                partition_size_info = [{\n",
    "                    \"partition_col\": part_col,\n",
    "                    \"mean_partition_size_gb\": round(mean_partition_size_gb, 6),\n",
    "                    \"scan_partitions\": scan_partitions,\n",
    "                    \"total_size_gb\": total_size_gb\n",
    "                }]\n",
    "            else:\n",
    "                partition_size_info = []\n",
    "            result[\"partition_size_info\"] = partition_size_info\n",
    "        \n",
    "        # Step 4: Analyze each column\n",
    "        print(f\"Performing column-level analysis for {table_name}...\")\n",
    "        schema_info = metadata[\"schema_info\"]\n",
    "        column_analyses = []\n",
    "        \n",
    "        for column_info in schema_info[\"columns\"]:\n",
    "            col_name = column_info[\"name\"]\n",
    "            col_type = column_info[\"type\"]\n",
    "            \n",
    "            # Analyze column quality (pass df_filtered and total_rows)\n",
    "            col_analysis = analyze_column_quality(df_filtered, col_name, col_type, total_rows)\n",
    "            column_analyses.append(col_analysis)\n",
    "        \n",
    "        result[\"column_analysis\"] = column_analyses\n",
    "        \n",
    "        # Step 5: Generate recommendations\n",
    "        recommendations = generate_recommendations(result, size_threshold_gb)\n",
    "        result[\"recommendations\"] = recommendations\n",
    "        \n",
    "        # Calculate assessment duration\n",
    "        assessment_end = datetime.now()\n",
    "        result[\"assessment_duration_seconds\"] = (assessment_end - assessment_start).total_seconds()\n",
    "        \n",
    "        print(f\"Assessment completed for {table_name} in {result['assessment_duration_seconds']:.2f} seconds\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        result[\"error\"] = str(e)\n",
    "        result[\"recommendations\"].append(f\"CRITICAL: Assessment failed - {str(e)}\")\n",
    "        print(f\"Assessment failed for {table_name}: {str(e)}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def generate_recommendations(assessment: Dict[str, Any], size_threshold: float) -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate actionable recommendations based on assessment results.\n",
    "    \n",
    "    Args:\n",
    "        assessment: Complete assessment results\n",
    "        size_threshold: Size threshold in GB for recommendations\n",
    "    \n",
    "    Returns:\n",
    "        List of recommendation strings\n",
    "    \"\"\"\n",
    "    recommendations = []\n",
    "    metadata = assessment.get(\"metadata\", {})\n",
    "    column_analysis = assessment.get(\"column_analysis\", [])\n",
    "    \n",
    "    # Size-based recommendations\n",
    "    size_gb = metadata.get(\"size_gb\", 0)\n",
    "    if size_gb > size_threshold:\n",
    "        recommendations.append(f\"PERFORMANCE: Large table ({size_gb:.1f} GB) - consider partitioning optimization\")\n",
    "    elif size_gb > size_threshold * 2:\n",
    "        recommendations.append(f\"CRITICAL: Very large table ({size_gb:.1f} GB) - requires cluster scaling\")\n",
    "    \n",
    "    # Partition recommendations\n",
    "    partition_cols = metadata.get(\"partition_columns\", [])\n",
    "    if len(partition_cols) == 0 and size_gb > 10:\n",
    "        recommendations.append(\"OPTIMIZATION: Table > 10GB without partitioning - consider adding partitions\")\n",
    "    elif len(partition_cols) > 5:\n",
    "        recommendations.append(\"WARNING: Too many partition columns may cause small files issue\")\n",
    "    \n",
    "    # Per-partition size recommendations using mean partition size\n",
    "    partition_size_info = assessment.get(\"partition_size_info\", [])\n",
    "    if partition_size_info:\n",
    "        for part_info in partition_size_info:\n",
    "            mean_size = part_info.get(\"mean_partition_size_gb\", 0)\n",
    "            if mean_size > size_threshold:\n",
    "                recommendations.append(f\"PERFORMANCE: Mean partition size ({mean_size:.2f} GB) exceeds threshold - consider repartitioning strategy\")\n",
    "    \n",
    "    # Column quality recommendations\n",
    "    critical_issues = 0\n",
    "    for col_analysis in column_analysis:\n",
    "        issues = col_analysis.get(\"issues\", [])\n",
    "        critical_issues += len(issues)\n",
    "        \n",
    "        # High null ratio warning\n",
    "        null_ratio = col_analysis.get(\"null_ratio\", 0)\n",
    "        if null_ratio > 0.5:\n",
    "            recommendations.append(f\"DATA QUALITY: Column '{col_analysis['column_name']}' has high null ratio ({null_ratio:.1%})\")\n",
    "        \n",
    "        # String quality issues\n",
    "        if col_analysis.get(\"illegal_chars_ratio\", 0) > 0:\n",
    "            recommendations.append(f\"DATA QUALITY: Column '{col_analysis['column_name']}' contains illegal characters\")\n",
    "        \n",
    "        if col_analysis.get(\"max_length\", 0) > 256:\n",
    "            recommendations.append(f\"PERFORMANCE: Column '{col_analysis['column_name']}' has very long strings (max: {col_analysis.get('max_length')})\")\n",
    "    \n",
    "    # Overall data quality assessment - FIXED: Any issue should mark as critical\n",
    "    if critical_issues == 0:\n",
    "        recommendations.append(\"HEALTHY: No critical data quality issues detected\")\n",
    "    else:\n",
    "        # ANY issue is considered critical for compliance\n",
    "        recommendations.append(f\"CRITICAL: {critical_issues} data quality issues detected - immediate attention required\")\n",
    "    \n",
    "    # History-based recommendations\n",
    "    history = metadata.get(\"history_summary\", {})\n",
    "    total_ops = history.get(\"total_operations\", 0)\n",
    "    if total_ops > 100:\n",
    "        recommendations.append(\"OPTIMIZATION: Table has extensive modification history - consider table optimization\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "print(\"Main assessment orchestration functions loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a16ab6bd-75bc-4b97-b221-5e162f9a2310",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Parallel Processing and Execution Engine\n",
    "\n",
    "def execute_quality_assessment(table_list: List[str], scan_partitions: int = 10) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Execute quality assessment for multiple tables in parallel using Spark.\n",
    "    \n",
    "    Args:\n",
    "        table_list: List of fully qualified table names\n",
    "        scan_partitions: Number of partitions to scan per table\n",
    "    \n",
    "    Returns:\n",
    "        Spark DataFrame with comprehensive assessment results\n",
    "    \"\"\"\n",
    "    print(f\"Starting quality assessment for {len(table_list)} tables...\")\n",
    "    execution_start = datetime.now()\n",
    "    \n",
    "    # Create assessment results list\n",
    "    assessment_results = []\n",
    "    \n",
    "    # Process each table (can be parallelized with Spark RDD if needed)\n",
    "    for i, table_name in enumerate(table_list, 1):\n",
    "        print(f\"\\nProcessing table {i}/{len(table_list)}: {table_name}\")\n",
    "        \n",
    "        try:\n",
    "            # Perform assessment\n",
    "            result = assess_table_quality(table_name, scan_partitions)\n",
    "            assessment_results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to assess {table_name}: {str(e)}\")\n",
    "            # Add failed result\n",
    "            failed_result = {\n",
    "                \"table_name\": table_name,\n",
    "                \"assessment_timestamp\": datetime.now().isoformat(),\n",
    "                \"exists\": False,\n",
    "                \"error\": str(e),\n",
    "                \"recommendations\": [f\"CRITICAL: Assessment failed - {str(e)}\"]\n",
    "            }\n",
    "            assessment_results.append(failed_result)\n",
    "    \n",
    "    execution_end = datetime.now()\n",
    "    total_duration = (execution_end - execution_start).total_seconds()\n",
    "    \n",
    "    print(f\"\\nCompleted assessment of {len(table_list)} tables in {total_duration:.2f} seconds\")\n",
    "    \n",
    "    # Convert results to Spark DataFrame for further processing\n",
    "    results_df = create_results_dataframe(assessment_results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def create_results_dataframe(assessment_results: List[Dict[str, Any]]) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Convert assessment results to structured Spark DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        assessment_results: List of assessment result dictionaries\n",
    "    \n",
    "    Returns:\n",
    "        Structured Spark DataFrame with flattened results\n",
    "    \"\"\"\n",
    "    flattened_results = []\n",
    "    \n",
    "    for result in assessment_results:\n",
    "        # Flatten the nested structure for DataFrame compatibility\n",
    "        columns_with_issues = [col.get(\"column_name\") for col in result.get(\"column_analysis\", []) if col.get(\"issues\", [])]\n",
    "        issues_dict = {col.get(\"column_name\"): col.get(\"issues\") for col in result.get(\"column_analysis\", []) if col.get(\"issues\", [])}\n",
    "        flat_result = {\n",
    "            \"table_name\": result.get(\"table_name\", \"\"),\n",
    "            \"assessment_timestamp\": result.get(\"assessment_timestamp\", \"\"),\n",
    "            \"exists\": result.get(\"exists\", False),\n",
    "            \"assessment_duration_seconds\": result.get(\"assessment_duration_seconds\", 0.0),\n",
    "            \n",
    "            # Metadata fields\n",
    "            \"size_gb\": result.get(\"metadata\", {}).get(\"size_gb\", 0.0),\n",
    "            \"partition_columns\": json.dumps(result.get(\"metadata\", {}).get(\"partition_columns\", [])),\n",
    "            \"column_count\": result.get(\"metadata\", {}).get(\"schema_info\", {}).get(\"column_count\", 0),\n",
    "            \"data_types\": json.dumps(result.get(\"metadata\", {}).get(\"schema_full\", {})),\n",
    "            \"total_operations\": result.get(\"metadata\", {}).get(\"history_summary\", {}).get(\"total_operations\", 0),\n",
    "            \"last_modified\": result.get(\"metadata\", {}).get(\"history_summary\", {}).get(\"last_modified\", \"\"),\n",
    "            \n",
    "            # Column analysis summary\n",
    "            \"total_columns_analyzed\": len(result.get(\"column_analysis\", [])),\n",
    "            \"columns_with_issues\": \", \".join(columns_with_issues),\n",
    "            \"avg_null_ratio\": round(\n",
    "                sum(col.get(\"null_ratio\", 0) for col in result.get(\"column_analysis\", [])) / \n",
    "                max(len(result.get(\"column_analysis\", [])), 1), 4\n",
    "            ),\n",
    "            \"max_string_length\": max(\n",
    "                (col.get(\"max_length\", 0) for col in result.get(\"column_analysis\", []) \n",
    "                 if \"string\" in col.get(\"data_type\", \"\").lower()), \n",
    "                default=0\n",
    "            ),\n",
    "            \"null_string_count\": max((col.get(\"null_string_count\", 0) for col in result.get(\"column_analysis\", []) if \"string\" in col.get(\"data_type\", \"\").lower()), default=0),\n",
    "            \"null_string_ratio\": max((col.get(\"null_string_ratio\", 0.0) for col in result.get(\"column_analysis\", []) if \"string\" in col.get(\"data_type\", \"\").lower()), default=0.0),\n",
    "            \n",
    "            # Recommendations and issues\n",
    "            \"total_recommendations\": len(result.get(\"recommendations\", [])),\n",
    "            \"has_critical_issues\": any(\"CRITICAL\" in rec for rec in result.get(\"recommendations\", [])),\n",
    "            \"recommendations\": json.dumps(result.get(\"recommendations\", [])),\n",
    "            \n",
    "            # Error handling\n",
    "            \"has_error\": \"error\" in result,\n",
    "            \"error_message\": result.get(\"error\", \"\"),\n",
    "            \n",
    "            # Add column_analysis as JSON string\n",
    "            \"column_analysis\": json.dumps(result.get(\"column_analysis\", []), default=decimal_default),\n",
    "            \"partition_size_info\": json.dumps(result.get(\"partition_size_info\", [])),\n",
    "            # Add issues as JSON string,\n",
    "            \"issues\": json.dumps(issues_dict)\n",
    "        }\n",
    "        \n",
    "        flattened_results.append(flat_result)\n",
    "    \n",
    "    # Define schema for the DataFrame\n",
    "    schema = StructType([\n",
    "        StructField(\"table_name\", StringType(), True),\n",
    "        StructField(\"assessment_timestamp\", StringType(), True),\n",
    "        StructField(\"exists\", BooleanType(), True),\n",
    "        StructField(\"assessment_duration_seconds\", FloatType(), True),\n",
    "        StructField(\"size_gb\", FloatType(), True),\n",
    "        StructField(\"partition_columns\", StringType(), True),\n",
    "        StructField(\"column_count\", IntegerType(), True),\n",
    "        StructField(\"data_types\", StringType(), True),\n",
    "        StructField(\"total_operations\", IntegerType(), True),\n",
    "        StructField(\"last_modified\", StringType(), True),\n",
    "        StructField(\"total_columns_analyzed\", IntegerType(), True),\n",
    "        # StructField(\"columns_with_issues\", IntegerType(), True),\n",
    "        StructField(\"columns_with_issues\", StringType(), True),\n",
    "        StructField(\"avg_null_ratio\", FloatType(), True),\n",
    "        StructField(\"max_string_length\", IntegerType(), True),\n",
    "        StructField(\"null_string_count\", IntegerType(), True),\n",
    "        StructField(\"null_string_ratio\", FloatType(), True),\n",
    "        StructField(\"total_recommendations\", IntegerType(), True),\n",
    "        StructField(\"has_critical_issues\", BooleanType(), True),\n",
    "        StructField(\"recommendations\", StringType(), True),\n",
    "        StructField(\"has_error\", BooleanType(), True),\n",
    "        StructField(\"error_message\", StringType(), True),\n",
    "        StructField(\"column_analysis\", StringType(), True),\n",
    "        StructField(\"partition_size_info\", StringType(), True),\n",
    "        StructField(\"issues\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    # Create DataFrame from results\n",
    "    results_df = spark.createDataFrame(flattened_results, schema)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "print(\"Parallel processing and execution engine loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28fa6a6c-d04c-4a69-81d5-ffe2a62081a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Execute Quality Assessment\n",
    "def databricks_table_quality_assessment()-> DataFrame:\n",
    "    \"\"\"\n",
    "    Main function to execute the Databricks Table Quality Assessment.\n",
    "    \"\"\"\n",
    "    # Parameters are already retrieved from widgets above\n",
    "    print(\"=\"*80)\n",
    "    print(\"DATABRICKS TABLE QUALITY ASSESSMENT\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Validate input parameters\n",
    "    if not table_list:\n",
    "        print(\"ERROR: No tables specified in table_list parameter\")\n",
    "        print(\"Please configure the table_list widget with comma-separated fully qualified table names\")\n",
    "    else:\n",
    "        print(f\"Configuration Summary:\")\n",
    "        print(f\"- Tables to assess: {len(table_list)}\")\n",
    "        print(f\"- Table list: {table_list}\")\n",
    "        print(f\"- Partition scan depth: {scan_partitions}\")\n",
    "        print(f\"- Size threshold: {size_threshold_gb} GB\")\n",
    "        print(f\"- Output format: {output_format}\")\n",
    "        \n",
    "        print(\"\\nStarting comprehensive table quality assessment...\")\n",
    "        \n",
    "        # Execute the assessment\n",
    "        results_df = execute_quality_assessment(table_list, scan_partitions)\n",
    "        \n",
    "        print(f\"\\nAssessment completed! Results summary:\")\n",
    "        print(f\"- Total tables processed: {results_df.count()}\")\n",
    "        print(f\"- Tables existing: {results_df.filter(col('exists') == True).count()}\")\n",
    "        print(f\"- Tables with critical issues: {results_df.filter(col('has_critical_issues') == True).count()}\")\n",
    "        print(f\"- Tables with errors: {results_df.filter(col('has_error') == True).count()}\")\n",
    "        \n",
    "        # Show quick summary statistics\n",
    "        print(\"\\nQuick Statistics:\")\n",
    "        summary_stats = results_df.filter(col('exists') == True).agg(\n",
    "            spark_sum('size_gb').alias('total_size_gb'),\n",
    "            avg('size_gb').alias('avg_size_gb'),\n",
    "            spark_max('size_gb').alias('max_size_gb'),\n",
    "            avg('column_count').alias('avg_columns'),\n",
    "            avg('avg_null_ratio').alias('overall_avg_null_ratio')\n",
    "        ).collect()[0]\n",
    "        \n",
    "        if summary_stats:\n",
    "            print(f\"- Total size across all tables: {summary_stats['total_size_gb']:.2f} GB\")\n",
    "            print(f\"- Average table size: {summary_stats['avg_size_gb']:.2f} GB\")\n",
    "            print(f\"- Largest table size: {summary_stats['max_size_gb']:.2f} GB\")\n",
    "            print(f\"- Average columns per table: {summary_stats['avg_columns']:.1f}\")\n",
    "            print(f\"- Overall average null ratio: {summary_stats['overall_avg_null_ratio']:.2%}\")\n",
    "\n",
    "        print(\"\\nQuality assessment execution completed successfully!\")\n",
    "        return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5086e0a7-4517-4a54-8ca6-050919a61860",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1754323833298}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      },
      "1": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"Recommendations\":442},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1754331357094}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 1
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Results Display and Reporting\n",
    "def detailed_assessment_results(results_df: DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Display detailed assessment results in a user-friendly format.\n",
    "    \"\"\"\n",
    "    ##############\n",
    "    # Results Display\n",
    "    ##############\n",
    "    \n",
    "\n",
    "\n",
    "    # Display main results table using Databricks display function\n",
    "    print(\"=\"*80)\n",
    "    print(\"DETAILED ASSESSMENT RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "    if results_df and not results_df.isEmpty():\n",
    "\n",
    "\n",
    "        # Parse partition columns and partition size info as arrays/structs for display\n",
    "        results_df = results_df.withColumn(\n",
    "            \"partition_cols\", from_json(col(\"partition_columns\"), ArrayType(StringType()))\n",
    "    )\n",
    "\n",
    "\n",
    "        # Parse partition_size_gb as mean partition size info from partition_size_info\n",
    "\n",
    "        partition_size_schema = ArrayType(StructType([\n",
    "            StructField(\"partition_col\", StringType(), True),\n",
    "            StructField(\"mean_partition_size_gb\", FloatType(), True),\n",
    "            StructField(\"scan_partitions\", IntegerType(), True),\n",
    "            StructField(\"total_size_gb\", FloatType(), True)\n",
    "        ]))\n",
    "\n",
    "\n",
    "        if \"partition_size_info\" in results_df.columns:\n",
    "            results_df = results_df.withColumn(\n",
    "                \"partition_size_gb\", from_json(col(\"partition_size_info\"), partition_size_schema)\n",
    "            )\n",
    "        else:\n",
    "            results_df = results_df.withColumn(\"partition_size_gb\", lit(None).cast(partition_size_schema))\n",
    "\n",
    "\n",
    "\n",
    "        # Parse new data_types (schema_full) as struct with columns and partition_columns\n",
    "        schema_full_type = StructType([\n",
    "            StructField(\"columns\", ArrayType(StructType([\n",
    "                StructField(\"col_name\", StringType(), True),\n",
    "                StructField(\"data_type\", StringType(), True),\n",
    "                StructField(\"comment\", StringType(), True)\n",
    "            ])), True),\n",
    "            StructField(\"partition_columns\", ArrayType(StructType([\n",
    "                StructField(\"col_name\", StringType(), True),\n",
    "                StructField(\"data_type\", StringType(), True),\n",
    "                StructField(\"comment\", StringType(), True)\n",
    "            ])), True)\n",
    "        ])\n",
    "        results_df = results_df.withColumn(\n",
    "            \"schema_full\", from_json(col(\"data_types\"), schema_full_type)\n",
    "        )\n",
    "\n",
    "        # --- Enhanced extraction for illegal_chars as struct array per column with character breakdown ---\n",
    "\n",
    "\n",
    "        def extract_illegal_chars_struct(col_analysis_json):\n",
    "            try:\n",
    "                analysis = json.loads(col_analysis_json) if isinstance(col_analysis_json, str) else col_analysis_json\n",
    "                if not analysis:\n",
    "                    return []\n",
    "                result = []\n",
    "                for col in analysis:\n",
    "                    if \"illegal_chars_count\" in col:\n",
    "                        result.append({\n",
    "                            \"column_name\": col.get(\"column_name\"),\n",
    "                            \"commas\": col.get(\"commas\", 0),\n",
    "                            \"semicolons\": col.get(\"semicolons\", 0),\n",
    "                            \"pipes\": col.get(\"pipes\", 0),\n",
    "                            \"tabs\": col.get(\"tabs\", 0),\n",
    "                            \"newlines\": col.get(\"newlines\", 0)\n",
    "                        })\n",
    "                return result\n",
    "            except Exception:\n",
    "                return []\n",
    "\n",
    "\n",
    "        extract_illegal_chars_struct_udf = udf(\n",
    "            extract_illegal_chars_struct,\n",
    "            ArrayType(StructType([\n",
    "                StructField(\"column_name\", StringType(), True),\n",
    "                StructField(\"commas\", IntegerType(), True),\n",
    "                StructField(\"semicolons\", IntegerType(), True),\n",
    "                StructField(\"pipes\", IntegerType(), True),\n",
    "                StructField(\"tabs\", IntegerType(), True),\n",
    "                StructField(\"newlines\", IntegerType(), True)\n",
    "    ])),\n",
    "        )\n",
    "\n",
    "\n",
    "        # If column_analysis is not present in results_df, add empty struct array\n",
    "        if 'column_analysis' not in results_df.columns:\n",
    "            results_df = results_df.withColumn(\n",
    "                \"illegal_chars\", lit([]).cast(ArrayType(StructType([\n",
    "                    StructField(\"column_name\", StringType(), True),\n",
    "                    StructField(\"commas\", IntegerType(), True),\n",
    "                    StructField(\"semicolons\", IntegerType(), True),\n",
    "                    StructField(\"pipes\", IntegerType(), True),\n",
    "                    StructField(\"tabs\", IntegerType(), True),\n",
    "                    StructField(\"newlines\", IntegerType(), True)\n",
    "    ])))\n",
    "            )\n",
    "        else:\n",
    "            results_df = results_df.withColumn(\n",
    "                \"illegal_chars\", extract_illegal_chars_struct_udf(col(\"column_analysis\"))\n",
    "    )\n",
    "\n",
    "\n",
    "        # --- Enhanced extraction for max_length for string columns only ---\n",
    "        def extract_max_length(col_analysis_json):\n",
    "            try:\n",
    "                analysis = json.loads(col_analysis_json) if isinstance(col_analysis_json, str) else col_analysis_json\n",
    "                if not analysis:\n",
    "                    return []\n",
    "                # Only return string columns with their max_length\n",
    "                return [\n",
    "                    {\"column_name\": col[\"column_name\"], \"max_length\": col[\"max_length\"]}\n",
    "                    for col in analysis\n",
    "                    if \"string\" in col.get(\"data_type\", \"\").lower() and col.get(\"max_length\") is not None\n",
    "                ]\n",
    "            except Exception:\n",
    "                return []\n",
    "\n",
    "        extract_max_length_udf = udf(\n",
    "            extract_max_length,\n",
    "            ArrayType(StructType([\n",
    "                StructField(\"column_name\", StringType(), True),\n",
    "                StructField(\"max_length\", IntegerType(), True)\n",
    "            ]))\n",
    "        )\n",
    "\n",
    "\n",
    "        if 'column_analysis' not in results_df.columns:\n",
    "            results_df = results_df.withColumn(\n",
    "                \"max_length\", lit([]).cast(ArrayType(StructType([\n",
    "                    StructField(\"column_name\", StringType(), True),\n",
    "                    StructField(\"max_length\", IntegerType(), True)\n",
    "                ])))\n",
    "            )\n",
    "        else:\n",
    "            results_df = results_df.withColumn(\"max_length\", extract_max_length_udf(col(\"column_analysis\")))\n",
    "\n",
    "        # Create a user-friendly view for display\n",
    "        display_df = results_df.select(\n",
    "            col(\"table_name\").alias(\"Table Name\"),\n",
    "            col(\"exists\").alias(\"Exists\"),\n",
    "            col(\"size_gb\").alias(\"Size (GB)\"),\n",
    "            col(\"partition_cols\").alias(\"Partition Columns\"),\n",
    "            col(\"partition_size_gb\").alias(\"Partition Size Info (GB)\"),\n",
    "            col(\"column_count\").alias(\"Columns\"),\n",
    "            col(\"schema_full\").alias(\"Schema (Types)\") ,\n",
    "            col(\"total_columns_analyzed\").alias(\"Analyzed Columns\"),\n",
    "            col(\"columns_with_issues\").alias(\"Columns with Issues\"),\n",
    "            col(\"avg_null_ratio\").alias(\"Avg Null Ratio\"),\n",
    "            col(\"illegal_chars\").alias(\"Illegal Chars (per col)\"),\n",
    "            col(\"max_length\").alias(\"Max Length (per col)\"),\n",
    "            col(\"null_string_count\").alias(\"'NULL' String Count\"),\n",
    "            col(\"null_string_ratio\").alias(\"'NULL' String Ratio\"),\n",
    "            col(\"has_critical_issues\").alias(\"Critical Issues\"),\n",
    "            col(\"total_recommendations\").alias(\"Recommendations Count\"),\n",
    "            col(\"assessment_duration_seconds\").alias(\"Duration (s)\")\n",
    "    ).orderBy(col(\"Size (GB)\").desc())\n",
    "\n",
    "\n",
    "        print(\"Main Assessment Results:\")\n",
    "        display(display_df)\n",
    "\n",
    "        \n",
    "        # Show tables with critical issues\n",
    "        critical_tables = results_df.filter(col(\"has_critical_issues\") == True)\n",
    "        critical_count = critical_tables.count()\n",
    "        \n",
    "        if critical_count > 0:\n",
    "            print(f\"\\nâ ï¸  CRITICAL ISSUES DETECTED ({critical_count} tables):\")\n",
    "            critical_display = critical_tables.select(\n",
    "                col(\"table_name\").alias(\"Table Name\"),\n",
    "                col(\"size_gb\").alias(\"Size (GB)\"),\n",
    "                col(\"recommendations\").alias(\"Recommendations\")\n",
    "            )\n",
    "            display(critical_display)\n",
    "        else:\n",
    "            print(\"\\nâ No critical issues detected across all tables!\")\n",
    "        \n",
    "        # Show failed assessments\n",
    "        failed_tables = results_df.filter(col(\"has_error\") == True)\n",
    "        failed_count = failed_tables.count()\n",
    "        \n",
    "        if failed_count > 0:\n",
    "            print(f\"\\nâ FAILED ASSESSMENTS ({failed_count} tables):\")\n",
    "            failed_display = failed_tables.select(\n",
    "                col(\"table_name\").alias(\"Table Name\"),\n",
    "                col(\"error_message\").alias(\"Error Message\")\n",
    "            )\n",
    "            display(failed_display)\n",
    "        \n",
    "        # Generate executive summary\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"EXECUTIVE SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        total_tables = results_df.count()\n",
    "        existing_tables = results_df.filter(col(\"exists\") == True).count()\n",
    "        # tables_with_issues = results_df.filter(col(\"columns_with_issues\") > 0).count()\n",
    "        tables_with_issues = results_df.filter(col(\"columns_with_issues\") != \"\").count()\n",
    "        \n",
    "        print(f\"\uD83D\uDCCA Assessment Overview:\")\n",
    "        print(f\"   â¢ Total tables evaluated: {total_tables}\")\n",
    "        print(f\"   â¢ Tables found: {existing_tables}\")\n",
    "        print(f\"   â¢ Tables missing: {total_tables - existing_tables}\")\n",
    "        print(f\"   â¢ Tables with data quality issues: {tables_with_issues}\")\n",
    "        print(f\"   â¢ Tables requiring immediate attention: {critical_count}\")\n",
    "        \n",
    "        if existing_tables > 0:\n",
    "            # Calculate health score\n",
    "            health_score = max(0, 100 - (critical_count / existing_tables * 50) - (tables_with_issues / existing_tables * 30))\n",
    "            print(f\"   â¢ Overall health score: {health_score:.1f}/100\")\n",
    "            \n",
    "            if health_score >= 90:\n",
    "                print(\"   \uD83D\uDFE2 Status: HEALTHY - Tables are in good condition\")\n",
    "            elif health_score >= 80:\n",
    "                print(\"   \uD83D\uDFE1 Status: FAIR - Some issues detected, monitoring recommended\")\n",
    "            else:\n",
    "                print(\"   \uD83D\uDD34 Status: CRITICAL - Immediate attention required\")\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"â No results available. Please run the assessment first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bba84da3-f7e6-4fd3-a15d-13eb9b353596",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"Recommendations\":484,\"Issues\":577},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1754336596618}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Detailed Column Analysis View\n",
    "def detailed_column_analysis(results_df: DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Provide detailed column-level analysis and recommendations.\n",
    "    \"\"\"\n",
    "    ##############\n",
    "    # Detailed Column Analysis\n",
    "    ##############\n",
    "    print(\"=\"*80)\n",
    "    print(\"DETAILED COLUMN ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    if results_df and not results_df.isEmpty():\n",
    "        \n",
    "        # Create detailed column analysis by expanding the assessment results\n",
    "        print(\"Generating detailed column analysis report...\")\n",
    "        \n",
    "        # Get tables that exist for detailed analysis\n",
    "        existing_tables = results_df.filter(col(\"exists\") == True).select(\"table_name\").collect()\n",
    "        \n",
    "        if existing_tables:\n",
    "            print(f\"Analyzing {len(existing_tables)} existing tables in detail...\")\n",
    "            \n",
    "            # For demonstration, show analysis for tables with issues\n",
    "            tables_with_issues = results_df.filter(\n",
    "                (col(\"exists\") == True) & \n",
    "                (col(\"columns_with_issues\") != \"\")\n",
    "            ).select(\"table_name\", \"columns_with_issues\", \"issues\", \"recommendations\")\n",
    "            \n",
    "            issues_count = tables_with_issues.count()\n",
    "            if issues_count > 0:\n",
    "                print(f\"\\n\uD83D\uDCCB Tables requiring attention ({issues_count} tables):\")\n",
    "                \n",
    "                tables_issues_display = tables_with_issues.select(\n",
    "                    col(\"table_name\").alias(\"Table Name\"),\n",
    "                    col(\"columns_with_issues\").alias(\"Columns with Issues\"),\n",
    "                    col(\"issues\").alias(\"Issues\"),\n",
    "                    col(\"recommendations\").alias(\"Recommendations\")\n",
    "                )\n",
    "                display(tables_issues_display)\n",
    "                \n",
    "                # Show data quality distribution\n",
    "                print(\"\\n\uD83D\uDCC8 Data Quality Distribution:\")\n",
    "                quality_distribution = results_df.filter(col(\"exists\") == True).select(\n",
    "                    when(col(\"avg_null_ratio\") < 0.05, \"Excellent (< 5% nulls)\")\n",
    "                    .when(col(\"avg_null_ratio\") < 0.15, \"Good (5-15% nulls)\")\n",
    "                    .when(col(\"avg_null_ratio\") < 0.30, \"Fair (15-30% nulls)\")\n",
    "                    .otherwise(\"Poor (> 30% nulls)\").alias(\"Data Quality Category\"),\n",
    "                    col(\"table_name\")\n",
    "                ).groupBy(\"Data Quality Category\").count().orderBy(\"count\")\n",
    "                \n",
    "                display(quality_distribution)\n",
    "            else:\n",
    "                print(\"\\nâ All existing tables have excellent column quality!\")\n",
    "            \n",
    "            # Show size distribution for capacity planning\n",
    "            print(\"\\n\uD83D\uDCBE Table Size Distribution (for capacity planning):\")\n",
    "            size_distribution = results_df.filter(col(\"exists\") == True).select(\n",
    "                when(col(\"size_gb\") < 1, \"Small (< 1 GB)\")\n",
    "                .when(col(\"size_gb\") < 10, \"Medium (1-10 GB)\")\n",
    "                .when(col(\"size_gb\") < 50, \"Large (10-50 GB)\")\n",
    "                .when(col(\"size_gb\") < 100, \"Very Large (50-100 GB)\")\n",
    "                .otherwise(\"Massive (> 100 GB)\").alias(\"Size Category\"),\n",
    "                col(\"table_name\"),\n",
    "                col(\"size_gb\")\n",
    "            ).groupBy(\"Size Category\").agg(\n",
    "                count(\"*\").alias(\"Table Count\"),\n",
    "                spark_sum(\"size_gb\").alias(\"Total Size (GB)\")\n",
    "            ).orderBy(\"Total Size (GB)\")\n",
    "            \n",
    "            display(size_distribution)\n",
    "            \n",
    "            # Performance recommendations\n",
    "            print(\"\\nâ¡ Performance Recommendations:\")\n",
    "            large_tables = results_df.filter(\n",
    "                (col(\"exists\") == True) & \n",
    "                (col(\"size_gb\") > size_threshold_gb)\n",
    "            ).count()\n",
    "            \n",
    "            unpartitioned_tables = results_df.filter(\n",
    "                (col(\"exists\") == True) & \n",
    "                (col(\"partition_columns\") == \"[]\") & \n",
    "                (col(\"size_gb\") > 10)\n",
    "            ).count()\n",
    "            \n",
    "            if large_tables > 0:\n",
    "                print(f\"   â¢ {large_tables} tables exceed size threshold ({size_threshold_gb} GB)\")\n",
    "                print(f\"   â¢ Consider cluster scaling for optimal performance\")\n",
    "            \n",
    "            if unpartitioned_tables > 0:\n",
    "                print(f\"   â¢ {unpartitioned_tables} large tables (>10GB) lack partitioning\")\n",
    "                print(f\"   â¢ Implement partitioning strategy for better query performance\")\n",
    "            \n",
    "            if large_tables == 0 and unpartitioned_tables == 0:\n",
    "                print(\"   â No performance issues detected!\")\n",
    "            \n",
    "        else:\n",
    "            print(\"â No existing tables found for detailed analysis\")\n",
    "\n",
    "    else:\n",
    "        print(\"â No results available. Please run the assessment first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8ea1b9e-926c-4b45-bcac-8533b08196f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Export and Persistence\n",
    "def export_and_persistence(results_df: DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Export results in various formats and persist for historical tracking.\n",
    "    \"\"\"\n",
    "    ##############\n",
    "    # Export and Persistence\n",
    "    ##############\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"EXPORT AND PERSISTENCE\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "    if results_df and not results_df.isEmpty():\n",
    "        \n",
    "        # Generate timestamp for file naming\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Prepare results for export based on selected format\n",
    "        if output_format == \"table\":\n",
    "            print(\"\uD83D\uDCCA Results displayed in table format above\")\n",
    "            \n",
    "        elif output_format == \"json\":\n",
    "            print(\"\uD83D\uDCC4 Exporting results to JSON format...\")\n",
    "            \n",
    "            # Convert to JSON-friendly format\n",
    "            json_results = results_df.toJSON().collect()\n",
    "            json_output = [json.loads(row) for row in json_results]\n",
    "            \n",
    "            # Save to DBFS or display\n",
    "            json_path = f\"/tmp/table_quality_assessment_{timestamp}.json\"\n",
    "            \n",
    "            # Write to temporary location for download\n",
    "            with open(f\"/databricks/driver/{json_path.split('/')[-1]}\", 'w') as f:\n",
    "                json.dump(json_output, f, indent=2)\n",
    "            \n",
    "            print(f\"   â JSON export saved to: {json_path}\")\n",
    "            print(f\"   \uD83D\uDCE5 File available for download from driver node\")\n",
    "            \n",
    "        elif output_format == \"csv\":\n",
    "            print(\"\uD83D\uDCC8 Exporting results to CSV format...\")\n",
    "            \n",
    "            # Simplify for CSV export (flatten complex fields)\n",
    "            csv_df = results_df.select(\n",
    "                \"table_name\",\n",
    "                \"exists\", \n",
    "                \"size_gb\",\n",
    "                \"column_count\",\n",
    "                \"columns_with_issues\",\n",
    "                \"avg_null_ratio\",\n",
    "                \"has_critical_issues\",\n",
    "                \"total_recommendations\",\n",
    "                \"assessment_duration_seconds\",\n",
    "                \"last_modified\"\n",
    "            )\n",
    "            \n",
    "            csv_path = f\"/tmp/table_quality_assessment_{timestamp}.csv\"\n",
    "            \n",
    "            # Write CSV (single partition for small datasets)\n",
    "            csv_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(csv_path)\n",
    "            \n",
    "            print(f\"   â CSV export saved to: {csv_path}\")\n",
    "            print(f\"   \uD83D\uDCE5 Use Databricks file download to retrieve CSV\")\n",
    "        \n",
    "        elif output_format == \"delta\":\n",
    "            print(\"\uD83D\uDCBE Persisting results as Delta table for historical tracking...\")\n",
    "            \n",
    "            # Add assessment metadata\n",
    "            enriched_results = results_df.withColumn(\"assessment_date\", date_format(current_timestamp(), \"yyyy-MM-dd\")) \\\n",
    "                                        .withColumn(\"assessment_run_id\", lit(timestamp)) \\\n",
    "                                        .withColumn(\"notebook_version\", lit(\"1.0\")) \\\n",
    "                                        .withColumn(\"scan_partitions_config\", lit(scan_partitions)) \\\n",
    "                                        .withColumn(\"size_threshold_config\", lit(size_threshold_gb))\n",
    "            \n",
    "            # Create Delta table path\n",
    "            delta_path = f\"/tmp/delta/table_quality_assessments\"\n",
    "            \n",
    "            try:\n",
    "                # Append to historical table (create if not exists)\n",
    "                enriched_results.write.mode(\"append\").option(\"mergeSchema\", \"true\").format(\"delta\").save(delta_path)\n",
    "                \n",
    "                print(f\"   â Results appended to Delta table: {delta_path}\")\n",
    "                print(f\"   \uD83D\uDD50 Historical data available for trend analysis\")\n",
    "                \n",
    "                # Create/update table in catalog if permissions allow\n",
    "                try:\n",
    "                    spark.sql(f\"\"\"\n",
    "                        CREATE TABLE IF NOT EXISTS table_quality_history\n",
    "                        USING DELTA\n",
    "                        LOCATION '{delta_path}'\n",
    "                    \"\"\")\n",
    "                    print(f\"   \uD83D\uDCCB Table 'table_quality_history' created/updated in catalog\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   â ï¸  Could not create catalog table (permissions): {str(e)}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   â Failed to save to Delta table: {str(e)}\")\n",
    "            \n",
    "        \n",
    "        print(\"\\n\uD83C\uDFAF Assessment Summary:\")\n",
    "        print(f\"   â¢ Assessment completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"   â¢ Results exported in {output_format} format\")\n",
    "        print(f\"   â¢ Run ID: {timestamp}\")\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"â No results available for export. Please run the assessment first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15b92e72-ab31-495a-ae25-4ab6471fe4d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = databricks_table_quality_assessment()\n",
    "    detailed_assessment_results(df)\n",
    "    detailed_column_analysis(df)\n",
    "    export_and_persistence(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de0d7de1-c952-4c48-bf70-936576be2606",
     "showTitle": false,
     "tableResultSettingsMap": {
      "1": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"Table Name\":233},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1754340596677}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 1
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Execute Main Function\n",
    "\n",
    "# Execute the main assessment workflow\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": {
    "autoRunOnWidgetChange": "no-auto-run"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7859687447634389,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "for_junior_databricks_table_quality_assessment",
   "widgets": {
    "output_format": {
     "currentValue": "table",
     "nuid": "24f5ccc7-fbb2-49bb-b19a-502c3f136718",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "table",
      "label": "Output format for results",
      "name": "output_format",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "table",
        "json",
        "csv",
        "delta"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "table",
      "label": "Output format for results",
      "name": "output_format",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "table",
        "json",
        "csv",
        "delta"
       ]
      }
     }
    },
    "scan_partitions": {
     "currentValue": "10",
     "nuid": "58dd9d6d-911f-450e-a59a-3a8d3122f0d4",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "10",
      "label": "Number of recent partitions to scan",
      "name": "scan_partitions",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "10",
      "label": "Number of recent partitions to scan",
      "name": "scan_partitions",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "size_threshold_gb": {
     "currentValue": "50",
     "nuid": "fcadb042-7a88-476e-b555-b9efdd147eb7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "50",
      "label": "Table size threshold in GB for recommendations",
      "name": "size_threshold_gb",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "50",
      "label": "Table size threshold in GB for recommendations",
      "name": "size_threshold_gb",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "table_list": {
     "currentValue": "workspace.default.customers,workspace.default.products,workspace.default.orders,workspace.default.order_items,workspace.default.payments,workspace.default.categories,workspace.default.suppliers,workspace.default.reviews,workspace.default.shipments,workspace.default.inventory",
     "nuid": "6de11961-c71c-4165-881c-e48da92f8081",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "catalog1.schema1.table1,catalog2.schema2.table2",
      "label": "Comma-separated list of fully qualified table names",
      "name": "table_list",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "catalog1.schema1.table1,catalog2.schema2.table2",
      "label": "Comma-separated list of fully qualified table names",
      "name": "table_list",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}